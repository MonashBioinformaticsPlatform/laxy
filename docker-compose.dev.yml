version: '3.7'
services:

  db:
    ports:
      # postgres accessible on the host at 5433 for debugging
      - "5433:5432"

  django:
    build:
      context: .
      dockerfile: ./docker/laxy/Dockerfile
    environment:
      # - LAXY_DEBUG=yes
      - LAXY_ADMIN_EMAIL=admin@example.com
      - LAXY_ADMIN_USERNAME=admin
      # - LAXY_ADMIN_PASSWORD=adminpass
      - LAXY_STATIC_ROOT=/usr/share/nginx/html/backend_static
      - LAXY_STATIC_URL=${LAXY_FRONTEND_URL-//dev.laxy.io:8002}/backend_static/
      # Number of gunicorn workers
      - WEB_CONCURRENCY=${WEB_CONCURRENCY-4}
    volumes:
      - .:/app
      - ./laxy_frontend/dist:/usr/share/nginx/html
    # Django app is publicly accessible without reverse proxy
#    ports:
#       - "8001:8001"
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "1"
    command: bash -c "sleep 10 &&
                      python3 manage.py collectstatic --no-input &&
                      python3 manage.py makemigrations --no-input &&
                      python3 manage.py migrate --no-input &&
                      python3 manage.py runserver 0.0.0.0:8001"
                      # gunicorn laxy.wsgi -b 0.0.0.0:8001 --forwarded-allow-ips='*' --worker-class gevent"
                      # Insecure: This leaks the admin password (eg via ps -ef).
                      # python manage.py shell -c \"from django.contrib.auth import get_user_model; User = get_user_model(); User.objects.filter(username='${LAXY_ADMIN_USERNAME}').count() or User.objects.create_superuser('${LAXY_ADMIN_USERNAME}', '${LAXY_ADMIN_EMAIL}', '${LAXY_ADMIN_PASSWORD}');\";"

  # Examine the logs to find the token to login to the Jupyter notebook
  # (eg docker-compose logs -f docker-compose.yml -f docker-compose.dev.yml shell-notebook )
  shell-notebook:
    build:
      context: .
      dockerfile: ./docker/laxy/Dockerfile
    environment:
      - LAXY_DEBUG=yes
      - LAXY_ADMIN_EMAIL=admin@example.com
      - LAXY_ADMIN_USERNAME=admin
    volumes:
      - .:/app
      - ./laxy_frontend/dist:/usr/share/nginx/html
    ports:
       - "8999:8999"
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "1"
    depends_on:
      - db
    command: bash -c "sleep 10 &&
                      pip3 install jupyter ipython django-extensions &&
                      python3 manage.py shell_plus --notebook"

  # NOTE: You may need to change the default Docker container memory to 4Gb when using
  #       this container, since `conda create` often exceeds 2Gb of RAM
  # We use port 2222 for OpenSSH so we can easily expose it to the host for debugging
  # without a port clash with the host SSH server.
  fake-cluster:
    image: fake-cluster:latest
    build:
      context: ./docker/fake-cluster
    volumes:
      - ./.fake-cluster-scratch:/scratch
    ports:
      - "2222:2222"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    restart: "unless-stopped"

  celeryd:
    build:
      context: .
      dockerfile: ./docker/laxy/Dockerfile
    command: bash -c "celery -A laxy worker -B -E -l info --broker=${LAXY_BROKER_URL}"
    volumes:
      - .:/app
    logging:
      driver: "json-file"
      options:
        max-size: "100k"
        max-file: "1"

  flower:
    environment:
      - FLOWER_BASIC_AUTH=user:pass
    ports:
      - "5556:5556"
    volumes:
      - .:/app

  nginx:
    command: >
      sh -c "
        echo -e '#!/bin/sh\n/usr/sbin/nginx -s reload' >/etc/periodic/daily/nginx-reload-config &&
        chmod +x /etc/periodic/daily/nginx-reload-config &&
        /usr/sbin/nginx -g 'daemon off;'
      "
    ports:
       # dev
       # - "8002:80"
       # - "443:443"
       - "8002:8002"
       - "8001:8001"
       - "80:80"
    depends_on:
      - ssl-certs-cron
    volumes:
      - ./laxy_frontend/dist:/usr/share/nginx/html
      - ./certs:/certs
      - ./nginx.conf:/etc/nginx/nginx.conf:ro

  ssl-certs-cron:
    # image: ssl-certs:latest'
    build:
      context: ./docker/ssl-certs/
    environment:
      # No quotes !
      - ACME_SSL_DOMAINS=${ACME_SSL_DOMAINS-dev.laxy.io dev-api.laxy.io}
    # Run certificate renewel/creation on startup if missing. Then run crond in foreground forever.
    command: sh -c "[ ! -f /certs/domain.key ] && /etc/periodic/daily/update-ssl-cert.sh; crond -l2 -f"
    volumes:
      - ./laxy_frontend/dist:/usr/share/nginx/html
      - ./certs:/certs

  splash:
    command: --disable-lua --disable-browser-caches --max-timeout 300
    ports:
      - "8050:8050"

# This method of 'cron-via-docker-restarts' will only work in Swarm mode, due to use of 'deploy'
#  ssl-certs-restart-daily:
#    image: alpine:3.8
#    command: >
#      sh -c '
#        DOMAINS="dev.laxy.io dev-api.laxy.io"
#        EXTRA_ARGS="" # -s = staging, -F = force renewal
#
#        /sbin/apk upgrade
#        /sbin/apk add --no-cache acme-client
#
#        /usr/bin/acme-client -a https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf -f /certs/account.key \
#                    -C /usr/share/nginx/html/.well-known/acme-challenge/ \
#                    -c /certs \
#                    -k /certs/domain.key \
#                    -Nnmev \
#                    $$EXTRA_ARGS \
#                    $$DOMAINS
#      '
#    deploy:
#      restart_policy:
#        condition: any
#        # Run every day
#        delay: 1d
#    volumes:
#      - ./laxy_frontend/dist:/usr/share/nginx/html
#      - ./certs:/certs
