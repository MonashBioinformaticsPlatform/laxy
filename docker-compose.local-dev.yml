volumes:
  fake-cluster-scratch:
  fake-archive-storage:


services:
  db:
    ports:
      # postgres accessible on the host at 5433 for debugging
      - "5433:5432"

  django:
    image: laxy:dev
    build:
      context: .
      dockerfile: ./docker/laxy/Dockerfile
    environment:
      - LAXY_DEBUG=yes
      - LAXY_SSL=no
      - LAXY_DATABASE_URL=postgres://postgres:postgres@db:5432/postgres
      - LAXY_BROKER_URL=amqp://guest@rabbitmq
      - LAXY_ADMIN_EMAIL=admin@example.com
      - LAXY_ADMIN_USERNAME=admin
      - LAXY_ADMIN_PASSWORD=adminpass
      - LAXY_SECRET_KEY=_do_please_change_this_in_production_
      - DEBUGGER_PORT=21004
    volumes:
      - .:/app
    # Django app is publicly accessible without reverse proxy
    ports:
      - "8001:8001"
      # Debugger port
      - "21004:21004"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    depends_on:
      - db
    command: bash -c "sleep 10 &&
      pip3 install -U ptvsd &&
      python3 manage.py migrate --no-input --run-syncdb &&
      python3 manage.py migrate --no-input &&
      python3 manage.py makemigrations --no-input &&
      python3 manage.py migrate --no-input &&
      python3 manage.py shell -c \"from os import environ as env; from django.contrib.auth import get_user_model; username = env.get('LAXY_ADMIN_USERNAME', 'admin'); User = get_user_model(); User.objects.filter(username=username).count() or User.objects.create_superuser(username, env.get('LAXY_ADMIN_EMAIL', None), env.get('LAXY_ADMIN_PASSWORD', None));\" &&
      python3 manage.py loaddata --app laxy_backend /app/docker/fake-cluster/fixtures.json &&
      LAXY_FRONTEND_API_URL=http://`hostname`:8001 python3 manage.py runserver 0.0.0.0:8001"
  # Examine the logs to find the token to login to the Jupyter notebook
  # (eg docker-compose logs -f docker-compose.yml -f docker-compose.dev.yml shell-notebook )
  shell-notebook:
    image: laxy:dev
    build:
      context: .
      dockerfile: ./docker/laxy/Dockerfile
    environment:
      - LAXY_DEBUG=yes
      - LAXY_SSL=no
      - LAXY_DATABASE_URL=postgres://postgres:postgres@db:5432/postgres
      - LAXY_BROKER_URL=amqp://guest@rabbitmq
      - LAXY_ADMIN_EMAIL=admin@example.com
      - LAXY_ADMIN_USERNAME=admin
      - LAXY_ADMIN_PASSWORD=adminpass
      - LAXY_SECRET_KEY=_do_please_change_this_in_production_
      - LAXY_SENTRY_DSN=
    volumes:
      - .:/app
    ports:
      - "8999:8999"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    depends_on:
      - db
    command: bash -c "sleep 10 &&
      pip3 install jupyter ipython ipykernel django-extensions &&
      python3 manage.py shell_plus --notebook"

  # This is npm + webpack, automatically rebuilding upon changes and serving on port 8002.
  # The source code directory on your host is mounted inside the container, so changes
  # you make will trigger automatic rebuilds (via webpack --watch).
  # If you prefer to run npm yourself outside a container, comment this out and run
  # "npm install && npm run server" manually.
  dev-frontend-server:
    image: node:10-buster
    working_dir: /app
    environment:
      - LAXY_DEBUG=yes
      - LAXY_SSL=no
    volumes:
      - .:/app
    # Frontend webpack-dev-server publicly accessible on port 8002
    ports:
      - "8002:8002"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    restart: "unless-stopped"
    command: bash -c "cd /app/laxy_frontend &&
      npm install &&
      npm run server"
    depends_on:
      - django

  # NOTE: You may need to change the default Docker container memory to 4Gb when using
  #       this container, since `conda create` often exceeds 2Gb of RAM
  #       Running with the docker-compose --compatibility flag should allow the
  #       'deploy.resources.limits.memory' setting in this service to be honoured.
  #
  # We use port 2222 for OpenSSH so we can easily expose it to the host for debugging
  # without a port clash with the host SSH server.
  fake-cluster:
    image: fake-cluster:latest
    build:
      context: ./docker/fake-cluster
    # We need to run as privileged to use apptainer inside docker
    privileged: true
    volumes:
      # - ./.fake-cluster-scratch:/scratch
      # We use a volume here since on OSX conda seems to have issues with host directory mounts
      - fake-cluster-scratch:/scratch
    ports:
      - "22222:22222"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    restart: "unless-stopped"
    depends_on:
      - django
    deploy:
      resources:
        limits:
          memory: "4000M"

  fake-archival-host:
    image: fake-cluster:latest
    build:
      context: ./docker/fake-cluster
    volumes:
      # - ./.fake-cluster-scratch:/scratch
      # We use a volume here since on OSX conda seems to have issues with host directory mounts
      - fake-archive-storage:/archive
    ports:
      - "2223:2222"
    logging:
      driver: "json-file"
      options:
        max-size: "10k"
        max-file: "1"
    restart: "unless-stopped"
    depends_on:
      - django

  splash:
    image: scrapinghub/splash:latest
    command: --disable-lua --disable-browser-caches --max-timeout 300
    ports:
      - "8050:8050"
    depends_on:
      - django
    #  - queue-high

  ##
  # Disabled services not required for simple local dev, overridden from base docker-compose.yml
  ##

  # For simple local development, we run in Django debug mode (LAXY_DEBUG=yes) with CELERY_ALWAYS_EAGER=True
  # so that celery tasks run non-async in the Django process. We don't need the celery daemon in this case.
  queue-high:
    image: alpine
    entrypoint:
      - /bin/echo
    command: "Service disabled"
    restart: "no"

  queue-low:
    image: alpine
    entrypoint:
      - /bin/echo
    command: "Service disabled"
    restart: "no"

  celery-beat:
    image: alpine
    entrypoint:
      - /bin/echo
    command: "Service disabled"
    restart: "no"

  # We don't need flower if we aren't using celeryd
  flower:
    image: alpine
    entrypoint:
      - /bin/echo
    command: "Service disabled"
    restart: "no"

  nginx:
    image: alpine
    entrypoint:
      - /bin/echo
    command: "Service disabled"
    restart: "no"
    ports:
      # dev
      - "9999:80"
