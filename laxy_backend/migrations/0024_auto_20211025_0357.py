# Generated by Django 2.2.20 on 2021-10-25 03:57

from django.db import migrations, transaction
from django.db.models import Count


def cleanup_dupes(apps, schema_editor):
    """
    Find duplicate File records (same fileset+path+name) and
    remove those without a location, keeping only the newest
    that has a location set.
    """

    db_alias = schema_editor.connection.alias
    File = apps.get_model("laxy_backend", "File")

    dupefiles = (
        File.objects.using(db_alias)
        .values("fileset", "path", "name")
        .annotate(records=Count("fileset"))
        .filter(records__gt=1)
    )
    for f in dupefiles:
        df = File.objects.filter(
            fileset=f["fileset"], path=f["path"], name=f["name"]
        ).order_by("created_time")
        # Keep the earliest one that has a location set
        keep = set([d for d in df if d.locations.filter(default=True).exists()][:1])
        # Delete the rest
        nuke = set(df).difference(keep)
        for _f in nuke:
            _f.delete()


class Migration(migrations.Migration):

    dependencies = [
        ("laxy_backend", "0023_auto_20210708_0545"),
    ]

    operations = [
        migrations.RunPython(cleanup_dupes),
    ]
